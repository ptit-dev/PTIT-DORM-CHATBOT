from random import random
import string
import sys
import os
import shutil
from dotenv import load_dotenv
import glob 
import requests
import json
from datetime import datetime
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings

# --- KH·∫ÆC PH·ª§C L·ªñI UNICODE TR√äN WINDOWS ---
if sys.stdout.encoding.lower() != 'utf-8':
    try:
        sys.stdout.reconfigure(encoding='utf-8')
    except AttributeError:
        pass

VECTOR_DB_PATH = "rag_chroma_db"
DATA_FOLDER = "data_documents"

# EMBEDDING_MODEL_NAME = "intfloat/multilingual-e5-large" 
# EMBEDDING_MODEL_NAME = "vinai/phobert-base"
EMBEDDING_MODEL_NAME = "bkai-foundation-models/vietnamese-bi-encoder"
CHUNK_SIZE = 1000
CHUNK_OVERLAP = 100
REPORT_FILE = "data_documents/ThongKeKTX.txt"


# --- C·∫§U H√åNH API (D√ôNG CHO B√ÅO C√ÅO T·ª∞ ƒê·ªòNG) ---
API_BASE_URL = os.getenv("API_BASE_URL")
# Th√¥ng tin ƒëƒÉng nh·∫≠p Admin t·ª´ bi·∫øn m√¥i tr∆∞·ªùng
ADMIN_USERNAME = os.getenv("ADMIN_USERNAME_ENV")
ADMIN_PASSWORD = os.getenv("ADMIN_PASSWORD_ENV")


# ---------------------- T·∫°o b√°o c√°o -------------------------------
def get_access_token():
    """M√¥ ph·ªèng ƒëƒÉng nh·∫≠p ƒë·ªÉ l·∫•y JWT Access Token."""
    print("--- 1. ƒêƒÇNG NH·∫¨P V√Ä L·∫§Y TOKEN T·ª∞ ƒê·ªòNG ---")
    login_url = f"{API_BASE_URL}/login"
    try:
        response = requests.post(
            login_url,
            headers={"Content-Type": "application/json"},
            json={"username": ADMIN_USERNAME, "password": ADMIN_PASSWORD}
        )
        response.raise_for_status()
        
        data = response.json()
        access_token = data.get('access_token')
        
        if access_token:
            print("‚úÖ ƒêƒÉng nh·∫≠p th√†nh c√¥ng! ƒê√£ l·∫•y Access Token.")
            return access_token
        else:
            print("üî¥ L·ªñI: ƒêƒÉng nh·∫≠p th√†nh c√¥ng nh∆∞ng kh√¥ng t√¨m th·∫•y access_token trong ph·∫£n h·ªìi.")
            return None
            
    except requests.exceptions.RequestException as e:
        status_code = e.response.status_code if e.response is not None else 'Kh√¥ng x√°c ƒë·ªãnh'
        print(f"üî¥ L·ªñI ƒêƒÇNG NH·∫¨P: Status Code {status_code} - Vui l√≤ng ki·ªÉm tra t√†i kho·∫£n v√† m·∫≠t kh·∫©u ho·∫∑c API URL.")
        return None

def fetch_data(token, endpoint, params=None):
    """G·ª≠i y√™u c·∫ßu GET ƒë·∫øn API Protected."""
    url = f"{API_BASE_URL}{endpoint}"
    headers = {
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json"
    }
    try:
        response = requests.get(url, headers=headers, params=params)
        response.raise_for_status()
        
        data = response.json()
        
        if isinstance(data, list):
            return data
        
        if isinstance(data, dict):
            return data.get('data', data)
        
        return data
        
    except requests.exceptions.RequestException as e:
        print(f"üî¥ L·ªói khi g·ªçi API {endpoint}: {e}")
        return [] 

def generate_report(token):
    """
    Thu th·∫≠p d·ªØ li·ªáu v√† t·∫°o b√°o c√°o KTX. 
    N·ªôi dung b√°o c√°o ƒë∆∞·ª£c ƒë·ªãnh d·∫°ng t·ªëi ∆∞u cho vi·ªác chia Chunk.
    """
    if token is None:
        print("üî¥ Khong the tao bao cao tu dong: Khong co token truy cap.")
        return False
        
    print("\n--- 2. B·∫ÆT ƒê·∫¶U T·∫†O B√ÅO C√ÅO KTX (D·ªÆ LI·ªÜU TH·ªúI GIAN TH·ª∞C) ---")
    
    # 1. THU TH·∫¨P D·ªÆ LI·ªÜU
    areas = fetch_data(token, "/api/v1/protected/dorm-areas")
    managers = fetch_data(token, "/api/v1/protected/managers")
    periods = fetch_data(token, "/api/v1/protected/registration-periods")
    applications = fetch_data(token, "/api/v1/protected/dorm-applications")
    contracts = fetch_data(token, "/api/v1/protected/contracts")
    duty_schedules = fetch_data(token, "/api/v1/protected/duty-schedules")

    # ƒê·∫£m b·∫£o d·ªØ li·ªáu l√† List
    areas = areas if isinstance(areas, list) else []
    managers = managers if isinstance(managers, list) else []
    periods = periods if isinstance(periods, list) else []
    applications = applications if isinstance(applications, list) else []
    contracts = contracts if isinstance(contracts, list) else []
    duty_schedules = duty_schedules if isinstance(duty_schedules, list) else []

    # 2. X·ª¨ L√ù V√Ä TH·ªêNG K√ä
    app_stats = {
        'total': len(applications),
        'pending': sum(1 for app in applications if app.get('status') == 'pending'),
        'approved': sum(1 for app in applications if app.get('status') == 'approved'),
        'rejected': sum(1 for app in applications if app.get('status') == 'rejected'),
    }

    contract_stats = {
        'total': len(contracts),
        'paid': sum(1 for c in contracts if c.get('status_payment') == 'paid'),
        'unpaid': sum(1 for c in contracts if c.get('status_payment') == 'unpaid'),
        'approved': sum(1 for c in contracts if c.get('status') == 'approved'),
    }
    
    active_periods = [p for p in periods if 'endtime' in p and datetime.strptime(p['endtime'].split('T')[0], '%Y-%m-%d').date() >= datetime.now().date()]
    
    
    # 3. T·∫†O N·ªòI DUNG B√ÅO C√ÅO TXT (T·ªêI ∆ØU CHUNKING)
    report_content = []
    
    # --- PH·∫¶N I: TH√îNG TIN T·ªîNG QUAN H·ªÜ TH·ªêNG ---
    report_content.append("I. TH√îNG TIN T·ªîNG QUAN H·ªÜ TH·ªêNG")
    report_content.append(f"T·ªïng s·ªë khu KTX ƒëang qu·∫£n l√Ω: {len(areas)}")
    report_content.append(f"Danh s√°ch khu KTX: {', '.join([area.get('name', 'N/A') for area in areas])}")
    report_content.append(f"T·ªïng s·ªë c√°n b·ªô qu·∫£n t√∫c: {len(managers)}")
    report_content.append(f"S·ªë ƒë·ª£t ƒëƒÉng k√Ω ƒëang/s·∫Øp di·ªÖn ra: {len(active_periods)}\n\n")
    report_content.append(f"G·ªìm c√°c ƒë·ª£t ƒëƒÉng k√Ω: {', '.join([p.get('name', 'N/A') for p in active_periods])}")
    report_content.append("\n")

    # --- PH·∫¶N II: DANH S√ÅCH C√ÅN B·ªò QU·∫¢N T√öC ---
    report_content.append("II. DANH S√ÅCH C√ÅN B·ªò QU·∫¢N T√öC")
    if managers:
        for manager in managers:
            name = manager.get('fullname', 'N/A')
            report_content.append(f"C√°n b·ªô: {name} | ƒê·ªãa ƒëi·ªÉm: KTX {manager.get('area_id', 'N/A')}")
        report_content.append("\n") 
    else:
        report_content.append("Hi·ªán kh√¥ng c√≥ danh s√°ch c√°n b·ªô qu·∫£n t√∫c.")
        report_content.append("\n")


    # --- PH·∫¶N III: T√åNH TR·∫†·∫†NG ƒê∆†N NGUY·ªÜN V·ªåNG ---
    report_content.append("III. T√åNH TR·∫†NG ƒê∆†N NGUY·ªÜN V·ªåNG")
    report_content.append(f"T·ªïng s·ªë ƒë∆°n nguy·ªán v·ªçng ƒë√£ nh·∫≠n: {app_stats['total']}")
    report_content.append(f"S·ªë ƒë∆°n ƒëang ch·ªù duy·ªát: {app_stats['pending']}")
    report_content.append(f"S·ªë ƒë∆°n ƒë√£ ƒë∆∞·ª£c duy·ªát: {app_stats['approved']}")
    report_content.append(f"S·ªë ƒë∆°n ƒë√£ b·ªã h·ªßy/t·ª´ ch·ªëi: {app_stats['rejected']}\n\n") 
    
    
    # --- PH·∫¶N IV: T√åNH TR·∫†NG H·ª¢P ƒê·ªíNG & THANH TO√ÅN ---
    report_content.append("IV. T√åNH TR·∫†NG H·ª¢P ƒê·ªíNG & THANH TO√ÅN")
    report_content.append(f"T·ªïng s·ªë h·ª£p ƒë·ªìng ƒë√£ t·∫°o: {contract_stats['total']}")
    report_content.append(f"S·ªë h·ª£p ƒë·ªìng ƒë√£ ƒë∆∞·ª£c duy·ªát ch√≠nh th·ª©c: {contract_stats['approved']}")
    report_content.append(f"S·ªë h·ª£p ƒë·ªìng ƒë√£ thanh to√°n: {contract_stats['paid']}")
    report_content.append(f"S·ªë h·ª£p ƒë·ªìng ch∆∞a thanh to√°n: {contract_stats['unpaid']}\n\n") 
    
    
    # --- PH·∫¶N V: CHI TI·∫æT C√ÅC ƒê·ª¢T ƒêƒÇNG K√ù ---
    report_content.append("V. CHI TI·∫æT C√ÅC ƒê·ª¢T ƒêƒÇNG K√ù")
    if periods:
        for p in periods:
            try:
                name = p.get('name', 'N/A')
                start_date = datetime.strptime(p['starttime'].split('T')[0], '%Y-%m-%d').strftime('%d/%m/%Y') if 'starttime' in p and p['starttime'] else 'N/A'
                end_date = datetime.strptime(p['endtime'].split('T')[0], '%Y-%m-%d').strftime('%d/%m/%Y') if 'endtime' in p and p['endtime'] else 'N/A'
                status = p.get('status', 'N/A')
                description = p.get('description', 'N/A')

                report_content.append(f"ƒê·ª£t: {name} | Th·ªùi gian: {start_date} - {end_date} | Tr·∫°ng th√°i: {status} | M√¥ t·∫£: {description}")
            except Exception as e:
                report_content.append(f"L·ªói x·ª≠ l√Ω th√¥ng tin ƒë·ª£t ƒëƒÉng k√Ω: {str(e)}")
        report_content.append("\n")
    else:
        report_content.append("Hi·ªán kh√¥ng c√≥ ƒë·ª£t ƒëƒÉng k√Ω n√†o.")
        report_content.append("\n")


    # --- PH·∫¶N VI: L·ªäCH TR·ª∞C C√ÅN B·ªò QU·∫¢N T√öC ---
    report_content.append("VI. L·ªäCH TR·ª∞C C√ÅN B·ªò QU·∫¢N T√öC")
    if duty_schedules:
        for schedule in duty_schedules:
            date_str = schedule.get('date', 'N/A')
            area_id = schedule.get('area_id', 'N/A')
            staff = schedule.get('staff', {})
            staff_name = staff.get('fullname', 'N/A')
            report_content.append(f"Ng√†y: {date_str} | Khu KTX: {area_id} | C√°n b·ªô: {staff_name}")
    else:
        report_content.append("Hi·ªán kh√¥ng c√≥ l·ªãch tr·ª±c n√†o ƒë∆∞·ª£c l√™n k·∫ø ho·∫°ch.")
    
    report_content.append("-" * 50) 

    # 4. L∆ØU V√ÄO FILE
    os.makedirs(os.path.dirname(REPORT_FILE), exist_ok=True)
    with open(REPORT_FILE, 'w', encoding='utf-8') as f:
        final_content = '\n'.join(report_content)
        # S·ª≠ d·ª•ng replace ƒë·ªÉ ƒë·∫£m b·∫£o ng·∫Øt ƒëo·∫°n m·∫°nh m·∫Ω h∆°n cho vi·ªác chia chunk (\n\n)
        f.write(final_content.replace('\n\n\n', '\n\n'))
    
    print(f"\n‚úÖ B√ÅO C√ÅO ƒê√É ƒê∆Ø·ª¢C T·∫†O TH√ÄNH C√îNG!")
    print(f"File b√°o c√°o n·∫±m t·∫°i: {os.path.abspath(REPORT_FILE)}")
    return True # Tr·∫£ v·ªÅ True n·∫øu b√°o c√°o ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng
    
def load_text_file_robustly(file_path):
    """
    H√†m ri√™ng ƒë·ªÉ t·∫£i file .txt m·ªôt c√°ch m·∫°nh m·∫Ω, th·ª≠ nhi·ªÅu m√£ h√≥a kh√°c nhau
    """
    try:
        # 1. Th·ª≠ t·∫£i b·∫±ng t·ª± ƒë·ªông d√≤ m√£ h√≥a (autodetect)
        loader = TextLoader(file_path, autodetect_encoding=True)
        return loader.load()
    except Exception as e:
        # 2. N·∫øu th·∫•t b·∫°i, th·ª≠ bu·ªôc m√£ h√≥a UTF-8
        try:
            loader = TextLoader(file_path, encoding='utf-8')
            return loader.load()
        except Exception as e_utf8:
            raise Exception(f"Kh√¥ng th·ªÉ t·∫£i file TXT ngay c·∫£ v·ªõi UTF-8. ·ªói g·ªëc: {e_utf8}")

# ---------------------- T·∫†O V√Ä L∆ØU DATABASE -------------------------------
def setup_database():
    """
    Th·ª±c hi·ªán 4 b∆∞·ªõc:
    1. T·ª± ƒë·ªông t·∫°o b√°o c√°o KTX (th√¥ng tin m·ªõi nh·∫•t).
    2. T·∫£i t√†i li·ªáu TXT v·ªõi x·ª≠ l√Ω l·ªói.
    3. Chia nh·ªè th√†nh chunks.
    4. T·∫°o embeddings v√† l∆∞u v√†o ChromaDB.
    """
    
    # 1. T·ª∞ ƒê·ªòNG T·∫†O B√ÅO C√ÅO M·ªöI NH·∫§T
    token = get_access_token()
    if token:
        generate_report(token)
    else:
        print("\n[B·ªè qua b∆∞·ªõc t·∫°o b√°o c√°o t·ª± ƒë·ªông]: ƒêƒÉng nh·∫≠p kh√¥ng th√†nh c√¥ng ho·∫∑c kh√¥ng c√≥ token.")


    print("\n--- B∆Ø·ªöC 1: X·ª¨ L√ù D·ªÆ LI·ªÜU ƒê·∫¶U V√Ä T·∫†O DATABASE ---") 
    
    documents = []
    if not os.path.exists(DATA_FOLDER):
        print(f"‚ùå L·ªói: Th∆∞ m·ª•c '{DATA_FOLDER}' kh√¥ng t·ªìn t·∫°i.")
        return None

    # 2. T·∫£i t√†i li·ªáu t·ª´ th∆∞ m·ª•c v√† x·ª≠ l√Ω l·ªói
    print(f"X·ª≠ l√Ω file txt")
    txt_file_paths = glob.glob(os.path.join(DATA_FOLDER, f"**/*.txt"), recursive=True)
    
    if not txt_file_paths:
        print("L·ªói: Kh√¥ng t√¨m th·∫•y b·∫•t k·ª≥ file txt n√†o trong th∆∞ m·ª•c")
        return None

    for file_path in txt_file_paths:
        try:
            documents.extend(load_text_file_robustly(file_path))
        except Exception as e:
            # print(f"‚ùå CANH BAO: Khong the tai file '{file_path}'. Loi: {e}")
            print (f"‚ùå CANH BAO: Kh√¥ng th·ªÉ t·∫£i file '{file_path}' do l·ªói: {e}")

    if not documents:
        print("L·ªói: Kh√¥ng t√¨m th·∫•y t√†i li·ªáu n√†o trong th∆∞ m·ª•c. Vui l√≤ng th√™m file v√†o.")
        return None

    print(f"‚úÖ ƒê√£ t·∫£i th√†nh c√¥ng {len(documents)} t√†i li·ªáu.")

    # 3. Chia nh·ªè t√†i li·ªáu th√†nh chunks
    print(f"-> Dang chia nho tai lieu thanh chunks (Kich thuoc: {CHUNK_SIZE}, Chong lan: {CHUNK_OVERLAP})...")
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=CHUNK_SIZE, 
        chunk_overlap=CHUNK_OVERLAP,
        separators=["\n\n", "\n", ". ", " ", ""]
    )
    chunks = text_splitter.split_documents(documents)
    print(f"‚úÖ Da chia nho thanh {len(chunks)} doan (chunks).")
    
    # 4. T·∫°o Embeddings v√† l∆∞u v√†o ChromaDB
    print(f"-> Dang khoi tao mo hinh nhung: {EMBEDDING_MODEL_NAME}...")
    embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME)

    # X√≥a database c≈© (n·∫øu c√≥) ƒë·ªÉ t·∫°o database m·ªõi
    if os.path.exists(VECTOR_DB_PATH):
        # x√≥a d·ªØ li·ªáu trong db ƒë√≥ ƒëi
        collection = Chroma(persist_directory=VECTOR_DB_PATH, embedding_function=embeddings)
        collection.delete_collection()
    print(f"-> Dang tao va luu Vector Database vao {VECTOR_DB_PATH}...")
    vectorstore = Chroma.from_documents(
        documents=chunks,
        embedding=embeddings,
        persist_directory=VECTOR_DB_PATH
    )
    print(f"‚úÖ Database da duoc tao va luu thanh cong!")
    return vectorstore


def test_retrieval(vectorstore):
    """
    Th·ª±c hi·ªán m·ªôt truy v·∫•n t√¨m ki·∫øm ƒë∆°n gi·∫£n ƒë·ªÉ ki·ªÉm tra t√≠nh nƒÉng Retrieval.
    """
    print("\n--- BUOC 2: KIEM TRA TINH NANG TRUY VAN (RETRIEVAL TEST) ---")
    
    # C√¢u h·ªèi th·ª≠ nghi·ªám
    test_question = "" 
    while test_question != "exit":
        test_question = input("Nhap cau hoi de kiem tra (tieng Viet khong dau) hoac 'exit' de thoat: ").strip()
        
        if test_question.lower() == 'exit':
            break

        # 1. Thi·∫øt l·∫≠p Retriever
        # Truy xu·∫•t 5 ƒëo·∫°n vƒÉn b·∫£n (chunks) li√™n quan nh·∫•t
        retriever = vectorstore.as_retriever(search_kwargs={"k": 5})
        
        # 2. Th·ª±c hi·ªán truy v·∫•n
        retrieved_docs = retriever.invoke(test_question)
        
        print(f"\n[QUERY] Cau hoi: {test_question}")
        print(f"‚úÖ Da truy xuat thanh cong {len(retrieved_docs)} doan van ban lien quan nhat.")
        
        print("\n--- NOI DUNG 5 DOAN VAN BAN TRUY VAN DUOC ---")
        for i, doc in enumerate(retrieved_docs):
            # Tr√≠ch xu·∫•t n·ªôi dung ng·∫Øn v√† ngu·ªìn
            content_snippet = doc.page_content.replace('\n', ' ')
            source = doc.metadata.get('source', 'nguon khong xac dinh')
            print(f"[{i+1}] Nguon: {source}")
            print(f"     Noi dung: {content_snippet}")
        print("----------------------------------------------------------")


if __name__ == "__main__":
    load_dotenv() 
    vectorstore = setup_database()

    if vectorstore:
        print("\n------------------------------------------------------------")
        print("T·∫†O B√ÅO C√ÅO V√Ä DATABASE TH√ÄNH C√îNG")
        print("------------------------------------------------------------")
        test_retrieval(vectorstore)
    else:
        print("\nüî¥ L·ªói x·∫£y ra trong qu√° tr√¨nh t·∫°o Vector Database")